# app.py
import io
import json
from datetime import datetime

import altair as alt
import numpy as np
import pandas as pd
import streamlit as st
from fpdf import FPDF
from PyPDF2 import PdfReader
from docx import Document

# --- IA de OpenAI (modo cl√°sico para compatibilidad) ---
import openai

OPENAI_KEY = st.secrets.get("OPENAI_API_KEY", "")
if OPENAI_KEY:
    openai.api_key = OPENAI_KEY

# -------------------------------------------------------------------
# CONFIGURACI√ìN GENERAL DE LA P√ÅGINA
# -------------------------------------------------------------------
st.set_page_config(
    page_title="Centinela Digital ‚Äì Integridad acad√©mica y cient√≠fica",
    page_icon="üõ°Ô∏è",
    layout="wide",
)

# -------------------------------------------------------------------
# ESTILOS B√ÅSICOS
# -------------------------------------------------------------------
st.markdown(
    """
    <style>
    .small-text {font-size: 0.8rem; color: #aaaaaa;}
    .risk-high {color:#ff4b4b; font-weight:bold;}
    .risk-medium {color:#ffb000; font-weight:bold;}
    .risk-low {color:#21c55d; font-weight:bold;}
    </style>
    """,
    unsafe_allow_html=True,
)

# -------------------------------------------------------------------
# UTILIDADES DE EXTRACCI√ìN DE TEXTO
# -------------------------------------------------------------------
def extract_text_from_pdf(file) -> str:
    try:
        reader = PdfReader(file)
        pages = [page.extract_text() or "" for page in reader.pages]
        return "\n".join(pages)
    except Exception as e:
        return f"[Error al leer PDF: {e}]"

def extract_text_from_docx(file) -> str:
    try:
        doc = Document(file)
        paragraphs = [p.text for p in doc.paragraphs]
        return "\n".join(paragraphs)
    except Exception as e:
        return f"[Error al leer DOCX: {e}]"


# -------------------------------------------------------------------
# AN√ÅLISIS B√ÅSICO (SIN IA) ‚Äì RESPALDO
# -------------------------------------------------------------------
def fallback_basic_analysis(text: str, rol: str, tipo: str) -> dict:
    """An√°lisis m√≠nimo cuando no hay API key o la IA falla."""
    n_chars = len(text)
    n_words = len(text.split())
    red_flags = []
    lower = text.lower()

    if "plagio" in lower or "copy" in lower:
        red_flags.append("Menci√≥n expl√≠cita a plagio o copia.")
    if "chatgpt" in lower or "inteligencia artificial" in lower:
        red_flags.append("Se menciona uso de IA en el texto.")
    if n_words < 150:
        red_flags.append("Texto muy corto para el tipo de producto declarado.")

    dim_scores = {
        "Metodol√≥gica": 40 if "m√©todo" in lower or "metodolog√≠a" in lower else 25,
        "√âtica": 50 if "consentimiento" in lower or "√©tica" in lower else 30,
        "Bibliogr√°fica": 45 if "doi" in lower or "referencias" in lower else 25,
        "Redacci√≥n / Coherencia": 55 if n_words > 200 else 30,
        "Uso de IA / Originalidad": 60 if "chatgpt" in lower else 35,
    }

    resumen = (
        "An√°lisis b√°sico sin IA de OpenAI. Se revis√≥ longitud, presencia de t√©rminos "
        "clave y posibles alertas m√≠nimas sobre plagio, √©tica y uso de IA."
    )

    return {
        "sentimiento_global": "neutral",
        "nivel_riesgo_global": "medio",
        "dimensiones": dim_scores,
        "kpis": {
            "n_palabras": n_words,
            "n_caracteres": n_chars,
            "n_red_flags": len(red_flags),
        },
        "red_flags": red_flags,
        "insights": [
            "Se recomienda complementar el an√°lisis con IA cuando se configure la API key.",
            "Revisar manualmente la coherencia metodol√≥gica y la solidez de las referencias.",
        ],
        "recomendaciones": [
            "Ampliar el marco te√≥rico y las referencias actualizadas.",
            "Incluir una secci√≥n expl√≠cita sobre consideraciones √©ticas.",
        ],
        "resumen": resumen,
    }


# -------------------------------------------------------------------
# AN√ÅLISIS CON IA DE OPENAI
# -------------------------------------------------------------------
def analyze_with_openai(text: str, rol: str, tipo: str) -> dict:
    """Llama a OpenAI para un an√°lisis profundo. Devuelve dict estructurado.
    Si algo falla, usa fallback_basic_analysis.
    """

    if not OPENAI_KEY or not text.strip():
        return fallback_basic_analysis(text, rol, tipo)

    system_prompt = (
        "Eres un experto en integridad cient√≠fica, bio√©tica y an√°lisis de textos "
        "acad√©micos. Analizas trabajos de estudiantes y docentes con mirada cr√≠tica "
        "pero formativa. Responde SIEMPRE en espa√±ol y SOLO con un JSON v√°lido."
    )

    user_prompt = f"""
Texto del trabajo (recortado si es muy largo):
\"\"\"{text[:8000]}\"\"\"  # si es muy largo, se corta a 8000 caracteres

Contexto:
- Rol de quien entrega el trabajo: {rol}
- Tipo de producto: {tipo}

Por favor devuelve SOLO un JSON con la siguiente estructura (sin comentarios):

{{
  "sentimiento_global": "positivo | neutro | negativo",
  "nivel_riesgo_global": "bajo | medio | alto",
  "dimensiones": {{
    "Metodol√≥gica": 0-100,
    "√âtica": 0-100,
    "Bibliogr√°fica": 0-100,
    "Redacci√≥n / Coherencia": 0-100,
    "Uso de IA / Originalidad": 0-100
  }},
  "kpis": {{
    "n_palabras": n√∫mero,
    "n_parrafos": n√∫mero,
    "porcentaje_primera_persona": 0-100,
    "porcentaje_citas_aproximado": 0-100
  }},
  "red_flags": [
    "descripci√≥n breve de cada alerta o posible mala pr√°ctica"
  ],
  "insights": [
    "insight anal√≠tico importante 1",
    "insight anal√≠tico importante 2"
  ],
  "recomendaciones": [
    "recomendaci√≥n priorizada 1",
    "recomendaci√≥n priorizada 2"
  ],
  "resumen": "p√°rrafo corto que resuma la situaci√≥n del caso"
}}

No incluyas texto fuera del JSON.
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            temperature=0.2,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )
        raw = response["choices"][0]["message"]["content"]
        data = json.loads(raw)
        return data
    except Exception as e:
        # En caso de error: an√°lisis b√°sico
        st.warning(
            f"No se pudo completar el an√°lisis con OpenAI ({e}). "
            "Se usar√° un an√°lisis b√°sico local."
        )
        return fallback_basic_analysis(text, rol, tipo)


# -------------------------------------------------------------------
# GENERACI√ìN DE INFORME PDF
# -------------------------------------------------------------------
def build_pdf_report(case_data: dict, analysis: dict) -> bytes:
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", "B", 16)
    pdf.cell(0, 10, "Centinela Digital - Informe del caso", ln=True)

    pdf.set_font("Arial", "", 11)
    pdf.ln(4)
    pdf.multi_cell(
        0,
        6,
        f"Fecha de an√°lisis: {case_data['fecha']}\n"
        f"Rol: {case_data['rol']}\n"
        f"Tipo de producto: {case_data['tipo_producto']}\n",
    )

    pdf.ln(2)
    pdf.set_font("Arial", "B", 12)
    pdf.cell(0, 8, "1. Resumen general", ln=True)
    pdf.set_font("Arial", "", 11)
    pdf.multi_cell(0, 6, analysis.get("resumen", ""))

    pdf.ln(2)
    pdf.set_font("Arial", "B", 12)
    pdf.cell(0, 8, "2. Indicadores clave (KPIs)", ln=True)
    pdf.set_font("Arial", "", 11)
    for k, v in analysis.get("kpis", {}).items():
        pdf.cell(0, 6, f"- {k}: {v}", ln=True)

    pdf.ln(2)
    pdf.set_font("Arial", "B", 12)
    pdf.cell(0, 8, "3. Matriz de riesgo por dimensiones", ln=True)
    pdf.set_font("Arial", "", 11)
    for dim, score in analysis.get("dimensiones", {}).items():
        pdf.cell(0, 6, f"- {dim}: {score}/100", ln=True)

    pdf.ln(2)
    pdf.set_font("Arial", "B", 12)
    pdf.cell(0, 8, "4. Red flags / Alertas", ln=True)
    pdf.set_font("Arial", "", 11)
    if analysis.get("red_flags"):
        for rf in analysis["red_flags"]:
            pdf.multi_cell(0, 6, f"- {rf}")
    else:
        pdf.multi_cell(0, 6, "- No se identificaron red flags cr√≠ticas.")

    pdf.ln(2)
    pdf.set_font("Arial", "B", 12)
    pdf.cell(0, 8, "5. Recomendaciones para el comit√© / tutor", ln=True)
    pdf.set_font("Arial", "", 11)
    for rec in analysis.get("recomendaciones", []):
        pdf.multi_cell(0, 6, f"- {rec}")

    pdf.ln(2)
    pdf.set_font("Arial", "I", 9)
    pdf.multi_cell(
        0,
        5,
        "Generado autom√°ticamente por Centinela Digital ‚Äì "
        "Modelo de monitoreo de integridad acad√©mica y cient√≠fica.\n"
        "Autor del software: Dr. Anderson D√≠az P√©rez.",
    )

    return pdf.output(dest="S").encode("latin-1")


# -------------------------------------------------------------------
# GENERACI√ìN DE INFORME WORD
# -------------------------------------------------------------------
def build_word_report(case_data: dict, analysis: dict) -> bytes:
    doc = Document()
    doc.add_heading("Centinela Digital - Informe del caso", level=1)

    doc.add_paragraph(f"Fecha de an√°lisis: {case_data['fecha']}")
    doc.add_paragraph(f"Rol: {case_data['rol']}")
    doc.add_paragraph(f"Tipo de producto: {case_data['tipo_producto']}")

    doc.add_heading("1. Resumen general", level=2)
    doc.add_paragraph(analysis.get("resumen", ""))

    doc.add_heading("2. Indicadores clave (KPIs)", level=2)
    for k, v in analysis.get("kpis", {}).items():
        doc.add_paragraph(f"{k}: {v}", style="List Bullet")

    doc.add_heading("3. Matriz de riesgo por dimensiones", level=2)
    for dim, score in analysis.get("dimensiones", {}).items():
        doc.add_paragraph(f"{dim}: {score}/100", style="List Bullet")

    doc.add_heading("4. Red flags / Alertas", level=2)
    if analysis.get("red_flags"):
        for rf in analysis["red_flags"]:
            doc.add_paragraph(rf, style="List Bullet")
    else:
        doc.add_paragraph("No se identificaron red flags cr√≠ticas.")

    doc.add_heading("5. Recomendaciones", level=2)
    for rec in analysis.get("recomendaciones", []):
        doc.add_paragraph(rec, style="List Bullet")

    doc.add_paragraph(
        "\nGenerado por Centinela Digital ‚Äì Autor del software: "
        "Dr. Anderson D√≠az P√©rez.",
        style=None,
    )

    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer.read()


# -------------------------------------------------------------------
# INICIALIZACI√ìN DEL HIST√ìRICO EN SESI√ìN
# -------------------------------------------------------------------
if "historial" not in st.session_state:
    st.session_state["historial"] = []  # lista de dicts


# -------------------------------------------------------------------
# ENCABEZADO
# -------------------------------------------------------------------
st.title("üõ°Ô∏è Centinela Digital")
st.subheader("Monitorizando la integridad acad√©mica y cient√≠fica con apoyo de IA")

st.markdown(
    """
    Esta es una versi√≥n inicial avanzada del sistema de monitoreo, dise√±ada para apoyar a 
    profesores, semilleros, comit√©s acad√©micos y comit√©s de √©tica en la detecci√≥n preliminar 
    de posibles inconsistencias, desviaciones o riesgos en trabajos acad√©micos y cient√≠ficos.
    """
)

st.markdown(
    '<p class="small-text">Autor del software y modelo conceptual: '
    '<strong>Dr. Anderson D√≠az P√©rez</strong>.</p>',
    unsafe_allow_html=True,
)

tab_analisis, tab_dashboard, tab_info = st.tabs(
    ["üîç Analizar un caso", "üìä Dashboards y Comit√© de √©tica", "‚ÑπÔ∏è Estado actual y pr√≥ximos pasos"]
)

# -------------------------------------------------------------------
# TAB 1 ‚Äì ANALIZAR UN CASO
# -------------------------------------------------------------------
with tab_analisis:
    st.header("1. Informaci√≥n b√°sica del caso")

    col1, col2 = st.columns(2)

    with col1:
        rol = st.selectbox(
            "Rol de quien entrega el trabajo",
            [
                "estudiante",
                "docente-investigador",
                "semillero de investigaci√≥n",
                "integrante de comit√© de √©tica",
                "otro",
            ],
        )

    with col2:
        tipo_producto = st.selectbox(
            "Tipo de producto",
            [
                "Art√≠culo cient√≠fico",
                "Ensayo acad√©mico",
                "Tesis / Trabajo de grado",
                "Informe t√©cnico",
                "Proyecto de investigaci√≥n",
                "Otro",
            ],
        )

    st.markdown("---")
    st.header("2. Contenido del trabajo")

    col_texto, col_archivo = st.columns([2, 1])

    with col_texto:
        fragmento = st.text_area(
            "Texto del trabajo (puedes pegar un fragmento relevante)",
            height=220,
            placeholder="Pega aqu√≠ un fragmento del trabajo, introducci√≥n, resumen o parte cr√≠tica‚Ä¶",
        )

    with col_archivo:
        st.markdown("**Carga opcional del archivo completo**")
        uploaded_file = st.file_uploader(
            "Formatos aceptados: PDF / Word (.docx)",
            type=["pdf", "docx"],
        )
        extra_text = ""
        if uploaded_file is not None:
            if uploaded_file.type == "application/pdf":
                extra_text = extract_text_from_pdf(uploaded_file)
            else:
                extra_text = extract_text_from_docx(uploaded_file)

            if extra_text.startswith("[Error"):
                st.error(extra_text)
            else:
                st.success("Archivo cargado correctamente. Se integrar√° al an√°lisis.")

    texto_para_analizar = (fragmento + "\n\n" + extra_text).strip()

    st.markdown("---")
    st.header("3. An√°lisis automatizado con IA")

    analizar = st.button("üöÄ Analizar caso con Centinela Digital")

    if analizar:
        if not texto_para_analizar:
            st.error("Por favor ingresa un fragmento de texto o carga un archivo para analizar.")
        else:
            with st.spinner("Analizando el caso con IA‚Ä¶"):
                analysis = analyze_with_openai(texto_para_analizar, rol, tipo_producto)

            fecha = datetime.now().strftime("%Y-%m-%d %H:%M")
            case_data = {
                "fecha": fecha,
                "rol": rol,
                "tipo_producto": tipo_producto,
                "texto_longitud": len(texto_para_analizar),
            }

            # Guardar en hist√≥rico de la sesi√≥n
            st.session_state["historial"].append(
                {
                    "fecha": fecha,
                    "rol": rol,
                    "tipo_producto": tipo_producto,
                    "nivel_riesgo_global": analysis.get("nivel_riesgo_global", ""),
                    **{f"dim_{k}": v for k, v in analysis.get("dimensiones", {}).items()},
                }
            )

            # ---------------- RESULTADOS PRINCIPALES ----------------
            st.subheader("Resultados principales")

            col_a, col_b, col_c = st.columns(3)
            sentimiento = analysis.get("sentimiento_global", "neutral")
            riesgo_global = analysis.get("nivel_riesgo_global", "medio")
            kpis = analysis.get("kpis", {})

            def riesgo_badge(level: str) -> str:
                level = level.lower()
                if level == "alto":
                    cls = "risk-high"
                elif level == "medio":
                    cls = "risk-medium"
                else:
                    cls = "risk-low"
                return f'<span class="{cls}">{level.upper()}</span>'

            col_a.markdown(f"**Sentimiento global:** `{sentimiento}`")
            col_b.markdown(
                f"**Nivel de riesgo global:** {riesgo_badge(riesgo_global)}",
                unsafe_allow_html=True,
            )
            col_c.markdown(f"**Palabras aproximadas:** `{kpis.get('n_palabras', '---')}`")

            st.markdown("### Matriz de riesgo por dimensiones")
            dim_df = pd.DataFrame(
                [
                    {"Dimensi√≥n": d, "Riesgo": v}
                    for d, v in analysis.get("dimensiones", {}).items()
                ]
            )

            if not dim_df.empty:
                try:
                    chart = (
                        alt.Chart(dim_df)
                        .mark_bar()
                        .encode(
                            x=alt.X("Riesgo:Q", scale=alt.Scale(domain=[0, 100])),
                            y=alt.Y("Dimensi√≥n:N", sort="-x"),
                            tooltip=["Dimensi√≥n", "Riesgo"],
                        )
                        .properties(height=220)
                    )
                    st.altair_chart(chart, use_container_width=True)
                except Exception as e:
                    st.warning(f"No se pudo renderizar el gr√°fico de riesgo: {e}")
                    st.dataframe(dim_df)
            else:
                st.info("No se encontraron datos de dimensiones de riesgo.")

            # ---------------- RED FLAGS E INSIGHTS ----------------
            st.markdown("### Red flags / Alertas detectadas")
            red_flags = analysis.get("red_flags", [])
            if red_flags:
                for rf in red_flags:
                    st.markdown(f"- ‚ö†Ô∏è {rf}")
            else:
                st.markdown("- ‚úÖ No se identificaron red flags cr√≠ticas.")

            st.markdown("### Principales insights anal√≠ticos")
            for ins in analysis.get("insights", []):
                st.markdown(f"- üí° {ins}")

            st.markdown("### Recomendaciones para mitigar riesgos")
            for rec in analysis.get("recomendaciones", []):
                st.markdown(f"- ü©∫ {rec}")

            st.markdown("### Resumen narrativo del caso")
            st.write(analysis.get("resumen", ""))

            # ---------------- DESCARGA DE INFORMES ----------------
            st.markdown("---")
            st.subheader("4. Informes autom√°ticos para comit√© / tutor")

            pdf_bytes = build_pdf_report(case_data, analysis)
            docx_bytes = build_word_report(case_data, analysis)

            col_pdf, col_docx = st.columns(2)
            col_pdf.download_button(
                label="üìÑ Descargar informe en PDF",
                data=pdf_bytes,
                file_name="informe_centinela_digital.pdf",
                mime="application/pdf",
            )
            col_docx.download_button(
                label="üìù Descargar informe en Word",
                data=docx_bytes,
                file_name="informe_centinela_digital.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            )

# -------------------------------------------------------------------
# TAB 2 ‚Äì DASHBOARDS Y COMIT√â DE √âTICA
# -------------------------------------------------------------------
with tab_dashboard:
    st.header("Panel de control para comit√©s de √©tica y programas acad√©micos")

    historial = st.session_state.get("historial", [])
    if not historial:
        st.info(
            "A√∫n no hay casos analizados en esta sesi√≥n. "
            "Vuelve a la pesta√±a *Analizar un caso* y genera al menos un an√°lisis."
        )
    else:
        df = pd.DataFrame(historial)

        st.subheader("Resumen general de casos analizados (solo esta sesi√≥n)")
        st.dataframe(df)

        col1, col2 = st.columns(2)

        # Distribuci√≥n por tipo de producto
        with col1:
            st.markdown("**Casos por tipo de producto**")
            tipo_counts = df["tipo_producto"].value_counts().reset_index()
            tipo_counts.columns = ["Tipo de producto", "Casos"]
            chart_tipo = (
                alt.Chart(tipo_counts)
                .mark_bar()
                .encode(
                    x="Casos:Q",
                    y="Tipo de producto:N",
                    tooltip=["Tipo de producto", "Casos"],
                )
                .properties(height=220)
            )
            st.altair_chart(chart_tipo, use_container_width=True)

        # Distribuci√≥n por nivel de riesgo
        with col2:
            st.markdown("**Casos por nivel de riesgo global**")
            riesgo_counts = df["nivel_riesgo_global"].value_counts().reset_index()
            riesgo_counts.columns = ["Nivel de riesgo", "Casos"]
            chart_riesgo = (
                alt.Chart(riesgo_counts)
                .mark_bar()
                .encode(
                    x="Casos:Q",
                    y="Nivel de riesgo:N",
                    tooltip=["Nivel de riesgo", "Casos"],
                )
                .properties(height=220)
            )
            st.altair_chart(chart_riesgo, use_container_width=True)

        st.markdown("### Matriz promedio de riesgo por dimensi√≥n")
        dim_cols = [c for c in df.columns if c.startswith("dim_")]
        if dim_cols:
            dim_avg = (
                df[dim_cols]
                .mean(numeric_only=True)
                .reset_index()
                .rename(columns={"index": "Dimensi√≥n", 0: "Riesgo promedio"})
            )
            dim_avg["Dimensi√≥n"] = dim_avg["Dimensi√≥n"].str.replace("dim_", "")
            chart_dim_avg = (
                alt.Chart(dim_avg)
                .mark_bar()
                .encode(
                    x=alt.X("Riesgo promedio:Q", scale=alt.Scale(domain=[0, 100])),
                    y="Dimensi√≥n:N",
                    tooltip=["Dimensi√≥n", "Riesgo promedio"],
                )
                .properties(height=220)
            )
            st.altair_chart(chart_dim_avg, use_container_width=True)
        else:
            st.info("A√∫n no hay informaci√≥n de dimensiones de riesgo en el hist√≥rico.")

        st.markdown(
            """
            Esta vista puede servir como **panel del comit√© de √©tica** o del **programa acad√©mico** 
            para identificar patrones de riesgo en semilleros, cursos o l√≠neas de investigaci√≥n 
            (por ejemplo, muchos casos con riesgo √©tico alto en cierto tipo de trabajo).
            """
        )

# -------------------------------------------------------------------
# TAB 3 ‚Äì INFORMACI√ìN Y PR√ìXIMOS PASOS
# -------------------------------------------------------------------
with tab_info:
    st.header("Estado actual y pr√≥ximos pasos del modelo Centinela Digital")

    st.markdown(
        """
        **Estado actual (versi√≥n web estable):**
        - Registro del rol y tipo de producto.
        - Carga directa de archivos PDF / Word.
        - An√°lisis automatizado con IA (o an√°lisis b√°sico si no hay API key).
        - Matriz de riesgo por dimensiones metodol√≥gica, √©tica, bibliogr√°fica, redacci√≥n y uso de IA.
        - Detecci√≥n de *red flags* y recomendaciones.
        - Generaci√≥n autom√°tica de informes en PDF y Word.
        - Panel de control con res√∫menes para comit√©s de √©tica y programas acad√©micos.

        **Pr√≥ximos m√≥dulos posibles:**
        - Persistencia de hist√≥ricos en base de datos institucional (semilleros, cohortes, l√≠neas).
        - Integraci√≥n con plataformas institucionales (Moodle, Teams, LMS propios).
        - M√≥dulo avanzado de verificaci√≥n de referencias (Crossref / PubMed).
        - Scoring espec√≠fico para convocatorias de investigaci√≥n y evaluaci√≥n de proyectos.
        """
    )

    st.markdown(
        """
        <p class="small-text">
        Este software fue conceptualizado y desarrollado como prototipo por 
        <strong>Dr. Anderson D√≠az P√©rez</strong>, integrando principios de bio√©tica, 
        integridad cient√≠fica e inteligencia artificial aplicada a la vigilancia acad√©mica.
        </p>
        """,
        unsafe_allow_html=True,
    )
