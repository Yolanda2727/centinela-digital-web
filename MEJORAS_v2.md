# Centinela Digital - Mejoras v2.0

## üìã Resumen

Este documento describe las mejoras implementadas en **Centinela Digital** para:

1. **Probar el flujo de trabajo con casos individuales**
2. **Ajustar el modelo de an√°lisis (reglas + IA)**
3. **Construir evidencia para una futura versi√≥n institucional**

---

## üöÄ Nuevos M√≥dulos

### 1. **test_cases.py** - Casos de Prueba Individuales

Proporciona 5 casos de prueba para validar el flujo completo:

#### Casos incluidos:

- **caso_bajo_riesgo**: Trabajo acad√©mico bien estructurado sin alertas (BAJO)
- **caso_riesgo_medio**: Art√≠culo con anomal√≠as moderadas (MEDIO)
- **caso_alto_riesgo**: Tesis con m√∫ltiples se√±ales de fraude (ALTO)
- **caso_edge_short**: Texto muy corto - caso l√≠mite
- **caso_investigador_externo**: Proyecto profesional de investigaci√≥n

#### Uso:

```python
from test_cases import get_all_test_cases, get_test_case

# Obtener todos los casos
casos = get_all_test_cases()

# Obtener caso espec√≠fico
caso = get_test_case("caso_bajo_riesgo")
```

---

### 2. **improved_analysis_model.py** - Modelo Mejorado de An√°lisis

Implementa un modelo de an√°lisis m√°s sofisticado con:

#### Caracter√≠sticas:

- **Pesos ponderados por dimensi√≥n**: Cada evidencia tiene un peso espec√≠fico
- **Factores contextuales**: Ajustes seg√∫n rol y tipo de producto
- **C√°lculo de confianza**: Indica cu√°n confiable es el an√°lisis
- **Recomendaciones autom√°ticas**: Basadas en dimensiones cr√≠ticas

#### Dimensiones de an√°lisis:

1. **Estilo y Autor√≠a** (40% estilo diferente + 60% defensa d√©bil)
2. **Tiempo y Ejecuci√≥n** (50% tiempo sospechoso + 50% sin borradores)
3. **Referencias y Datos** (40% referencias raras + 60% datos inconsistentes)
4. **Presentaci√≥n** (100% im√°genes sospechosas)

#### Factores contextuales:

| Rol | Factor |
|-----|--------|
| Estudiante | 1.0 |
| Docente-investigador | 0.7 |
| Coinvestigador externo | 0.6 |

#### Uso:

```python
from improved_analysis_model import analyze_with_improved_model

resultado = analyze_with_improved_model(
    evidencias={
        "estilo_diferente": 1,
        "tiempo_sospechoso": 0,
        # ... m√°s evidencias
    },
    rol="Estudiante",
    tipo_producto="Ensayo",
    num_evidencias_marked=3
)

print(resultado["overall_score"])      # 0-100
print(resultado["overall_level"])      # BAJO/MEDIO/ALTO
print(resultado["confidence"])         # 0.0-1.0
print(resultado["recommendations"])    # Lista de acciones
```

---

### 3. **database.py** - Persistencia en Base de Datos

Almacena hist√≥ricos completos para an√°lisis institucional:

#### Tablas:

- **casos**: Registro principal de an√°lisis
- **red_flags**: Alertas espec√≠ficas por caso
- **recomendaciones**: Acciones sugeridas
- **kpis**: Indicadores de desempe√±o
- **estadisticas_globales**: Agregados diarios

#### Uso:

```python
from database import CentinelaDatabase

db = CentinelaDatabase()

# Guardar un caso
caso_id = db.guardar_caso({
    "rol": "Estudiante",
    "tipo_producto": "Ensayo",
    "riesgo_score": 45,
    "nivel_riesgo": "MEDIO",
    # ...
})

# Recuperar
caso = db.obtener_caso(caso_id)

# Listar con filtros
casos_alto_riesgo = db.listar_casos(filtro_nivel="ALTO", limite=50)

# Estad√≠sticas
stats = db.obtener_estadisticas()
resumen = db.obtener_resumen_institucion()
```

---

### 4. **institutional_metrics.py** - M√©tricas Institucionales

Genera reportes agregados para decisiones estrat√©gicas:

#### Clases:

**InstitucionalMetrics**
- `calcular_tasa_riesgo()`: Distribuci√≥n por nivel
- `calcular_por_rol()`: An√°lisis desagregado por rol
- `calcular_por_producto()`: An√°lisis desagregado por tipo
- `identificar_patrones()`: Red flags frecuentes y anomal√≠as
- `generar_reporte_ejecutivo()`: Reporte completo para administraci√≥n
- `comparar_periodos()`: An√°lisis de cambios entre per√≠odos

**FollowUpMetrics**
- `calcular_evolucion_temporal()`: Tendencias a trav√©s del tiempo

#### Uso:

```python
from institutional_metrics import InstitucionalMetrics, FollowUpMetrics

# Reporte ejecutivo
reporte = InstitucionalMetrics.generar_reporte_ejecutivo(casos)

print(reporte["tasas_por_nivel"])          # {"ALTO": 25.0, "MEDIO": 50.0, ...}
print(reporte["metricas_por_rol"])         # An√°lisis por rol
print(reporte["patrones_detectados"])      # Red flags frecuentes
print(reporte["recomendaciones_estrategicas"])  # Acciones sugeridas

# Evoluci√≥n temporal
evolucion = FollowUpMetrics.calcular_evolucion_temporal(
    casos_historicos, 
    agrupacion="mensual"
)
```

---

### 5. **test_runner.py** - Suite de Testing

Script ejecutable que prueba todo el flujo:

#### Tests incluidos:

1. ‚úì Estructura de casos de prueba
2. ‚úì An√°lisis de cada caso individual
3. ‚úì Validaci√≥n del modelo mejorado
4. ‚úì Persistencia en base de datos
5. ‚úì Generaci√≥n de reportes institucionales

#### Ejecuci√≥n:

```bash
# Ejecutar todos los tests
python test_runner.py

# Con salida verbose
python test_runner.py --verbose
```

---

## üìä Flujo de Trabajo Mejorado

### Antes (versi√≥n anterior):

```
Entrada ‚Üí Matriz binaria ‚Üí OpenAI ‚Üí Reporte PDF
```

### Ahora (versi√≥n mejorada):

```
Entrada 
  ‚Üì
An√°lisis por reglas ponderadas
  ‚Üì
Factores contextuales aplicados
  ‚Üì
OpenAI (an√°lisis de sentimiento + IA)
  ‚Üì
Validaci√≥n de confianza
  ‚Üì
Recomendaciones autom√°ticas
  ‚Üì
Persistencia en BD
  ‚Üì
M√©tricas institucionales
  ‚Üì
Reportes PDF + Reportes ejecutivos
```

---

## üîß Integraci√≥n con app.py

Para integrar las mejoras en la aplicaci√≥n Streamlit existente:

```python
# En app.py, a√±adir estos imports
from improved_analysis_model import analyze_with_improved_model
from database import db
from institutional_metrics import InstitucionalMetrics

# Reemplazar la l√≥gica de an√°lisis actual con:
resultado_mejorado = analyze_with_improved_model(
    evidencias,
    rol,
    tipo_producto,
    num_evidencias_marked=sum(evidencias.values())
)

# Guardar en BD
db.guardar_caso({
    "rol": rol,
    "tipo_producto": tipo_producto,
    "riesgo_score": resultado_mejorado["overall_score"],
    "nivel_riesgo": resultado_mejorado["overall_level"],
    "confianza": resultado_mejorado["confidence"],
    # ... m√°s datos
})
```

---

## üìà Evidencia Construida para Versi√≥n Institucional

### Datos capturados:

1. **Por caso individual**:
   - Rol del autor
   - Tipo de producto
   - Puntaje de riesgo (0-100)
   - Nivel de riesgo (BAJO/MEDIO/ALTO)
   - Confianza del an√°lisis
   - Red flags detectadas
   - Recomendaciones
   - KPIs de seguimiento

2. **Por instituci√≥n** (agregados):
   - Distribuci√≥n de riesgo por per√≠odo
   - Tendencias por rol
   - Tendencias por tipo de producto
   - Patrones de red flags m√°s frecuentes
   - Anomal√≠as detectadas
   - Recomendaciones estrat√©gicas

### Reportes posibles:

- üìä Tablero diario de casos
- üìà Tendencias mensales
- üë• An√°lisis por programa acad√©mico
- üéØ Recomendaciones para comit√© de √©tica
- üìã Validaci√≥n de mejoras tras intervenciones

---

## üß™ Ejemplo de Ejecuci√≥n Completa

```python
from test_cases import get_test_case
from improved_analysis_model import analyze_with_improved_model, validate_analysis
from database import db
from institutional_metrics import InstitucionalMetrics

# 1. Obtener caso de prueba
caso = get_test_case("caso_alto_riesgo")

# 2. Analizar con modelo mejorado
resultado = analyze_with_improved_model(
    caso["evidencias"],
    caso["rol"],
    caso["tipo_producto"],
)

# 3. Validar
validacion = validate_analysis(resultado, expected_level=caso["expected_risk_level"])
print(f"V√°lido: {validacion['is_valid']}")

# 4. Guardar en BD
caso_id = db.guardar_caso({
    "rol": caso["rol"],
    "tipo_producto": caso["tipo_producto"],
    "riesgo_score": resultado["overall_score"],
    "nivel_riesgo": resultado["overall_level"],
    "confianza": resultado["confidence"],
})

# 5. Generar m√©tricas
todos_casos = db.listar_casos(limite=100)
reporte = InstitucionalMetrics.generar_reporte_ejecutivo(todos_casos)

print(f"Casos analizados: {reporte['resumen_general']['total_casos_analizados']}")
print(f"Tasa de riesgo: {reporte['tasas_por_nivel']}")
print(f"Recomendaciones: {reporte['recomendaciones_estrategicas']}")
```

---

## üìù Requisitos Adicionales

Si usas las nuevas caracter√≠sticas, actualiza `requirements.txt`:

```bash
pip install sqlite3  # Usualmente ya incluido en Python
```

---

## ‚úÖ Checklist de Validaci√≥n

- [x] 5 casos de prueba con diferentes niveles de riesgo
- [x] Modelo de an√°lisis con pesos ponderados
- [x] Factores contextuales por rol y producto
- [x] Persistencia completa en base de datos
- [x] M√©tricas agregadas para an√°lisis institucional
- [x] Suite completa de tests automatizados
- [x] Documentaci√≥n de integraci√≥n
- [x] Ejemplos de uso

---

## üîÆ Pr√≥ximas Fases Sugeridas

1. **Fase 2**: Integraci√≥n con Streamlit UI
2. **Fase 3**: Paneles comparativos por programa/cohorte
3. **Fase 4**: API REST para integraci√≥n institucional
4. **Fase 5**: Machine learning para mejora continua del modelo
5. **Fase 6**: Integraci√≥n con sistemas de gesti√≥n acad√©mica

---

**Versi√≥n**: 2.0  
**Fecha**: Enero 2026  
**Autor**: Prof. Anderson D√≠az P√©rez (Centinela Digital)  
**Estado**: Listo para testing e integraci√≥n
